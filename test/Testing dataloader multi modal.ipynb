{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d72a98-cbad-49bc-8ca2-812e6c5f13c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:29:13,389 - INFO - Starting an experimento in model path = ./experiments/baseline_wavlmbase_robertabase\n",
      "2024-12-26 23:29:13,391 - INFO - Using ssl = microsoft/wavlm-base LR = 1e-05 Epochs = 20 Batch size = 32 Accum steps = 2\n",
      "2024-12-26 23:29:13,392 - INFO - Using balanced batch = False\n",
      "2024-12-26 23:29:13,393 - INFO - Using normalize wav = False\n",
      "2024-12-26 23:29:13,394 - INFO - Using Timbre Perturbation = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 1.2440944881889764, 'Sad': 1.327941642879797, 'Happy': 0.5009271998564335, 'Surprise': 2.840569877883311, 'Fear': 7.476785714285715, 'Disgust': 5.847765363128492, 'Contempt': 3.356312625250501, 'Neutral': 0.28635912868036795}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:29:15,586 - INFO - Class weights: tensor([1.2441, 1.3279, 0.5009, 2.8406, 7.4768, 5.8478, 3.3563, 0.2864],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2441, 1.3279, 0.5009, 2.8406, 7.4768, 5.8478, 3.3563, 0.2864],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████████| 25258/25258 [01:48<00:00, 233.27it/s]"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# Local modules\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "# 3rd-Party Modules\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import librosa\n",
    "import copy\n",
    "import logging\n",
    "import time \n",
    "\n",
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel\n",
    "import importlib\n",
    "# Self-Written Modules\n",
    "sys.path.append('../')\n",
    "from benchmark import net\n",
    "from benchmark import utils\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--seed\", type=int, default=7)\n",
    "# # parser.add_argument(\"--ssl_type\", type=str, default=\"wavlm-large\")\n",
    "# # parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "# # parser.add_argument(\"--accumulation_steps\", type=int, default=1)\n",
    "# # parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "# # parser.add_argument(\"--lr\", type=float, default=0.001)\n",
    "# # parser.add_argument(\"--model_path\", type=str, default=\"./temp\")\n",
    "# parser.add_argument(\"--config_path\", type=str, default=\"./configs/config_cat.json\")\n",
    "# # parser.add_argument(\"--head_dim\", type=int, default=1024)\n",
    "\n",
    "# # parser.add_argument(\"--pooling_type\", type=str, default=\"AttentiveStatisticsPooling\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "# config_path = \"configs/config_cat.json\"\n",
    "config_path = '../configs/config_cat_wavlmbase_robertabase.json'\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "audio_path = config[\"wav_dir\"]\n",
    "text_path = config[\"txt_dir\"]\n",
    "label_path = config[\"label_path\"]\n",
    "\n",
    "SSL_TYPE = utils.get_ssl_type(config['ssl_type'])\n",
    "assert SSL_TYPE != None, print(\"Invalid SSL type!\")\n",
    "BATCH_SIZE = config['batch_size']\n",
    "ACCUMULATION_STEP = config['accum_step']\n",
    "assert (ACCUMULATION_STEP > 0) and (BATCH_SIZE % ACCUMULATION_STEP == 0)\n",
    "EPOCHS= config['epochs']\n",
    "LR=config['lr']\n",
    "MODEL_PATH = config['model_path']\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "HEAD_DIM = config['head_dim']\n",
    "POOLING_TYPE = config['pooling_type']\n",
    "WC = config[\"weight_decay\"]\n",
    "DROPOUT = config[\"dropout_head\"]\n",
    "USE_TIMBRE_PERTURB = config['use_timbre_perturb']\n",
    "TP_PROB = config['tp_prob']\n",
    "# utils.set_deterministic(args.seed)\n",
    "# SSL_TYPE = utils.get_ssl_type(args.ssl_type)\n",
    "# assert SSL_TYPE != None, print(\"Invalid SSL type!\")\n",
    "# BATCH_SIZE = args.batch_size\n",
    "# ACCUMULATION_STEP = args.accumulation_steps\n",
    "# assert (ACCUMULATION_STEP > 0) and (BATCH_SIZE % ACCUMULATION_STEP == 0)\n",
    "# EPOCHS=args.epochs\n",
    "# LR=args.lr\n",
    "# MODEL_PATH = args.model_path\n",
    "# os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# Start logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(MODEL_PATH, '%s-%d.log' % ('loggingtxt', time.time()))),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "\n",
    "# print(config[\"use_balanced_batch\"])\n",
    "try:\n",
    "    balanced_batch = config[\"use_balanced_batch\"]\n",
    "except:\n",
    "    balanced_batch = False\n",
    "\n",
    "try:\n",
    "    normalize_wav = config[\"normalize_wav\"]\n",
    "except:\n",
    "    normalize_wav = True\n",
    "\n",
    "logger.info(f\"Starting an experimento in model path = {MODEL_PATH}\")\n",
    "logger.info(f\"Using ssl = {SSL_TYPE} LR = {LR} Epochs = {EPOCHS} Batch size = {BATCH_SIZE} Accum steps = {ACCUMULATION_STEP}\")\n",
    "logger.info(f\"Using balanced batch = {balanced_batch}\")\n",
    "logger.info(f\"Using normalize wav = {normalize_wav}\")\n",
    "logger.info(f\"Using Timbre Perturbation = {USE_TIMBRE_PERTURB}\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "label_df = pd.read_csv(label_path)\n",
    "text_df = pd.read_csv(text_path)\n",
    "df = label_df.merge(text_df, on = 'FileName', how = 'left')\n",
    "# Filter out only 'Train' samples\n",
    "train_df = df[df['Split_Set'] == 'Train']\n",
    "\n",
    "# Classes (emotions)\n",
    "classes = ['Angry', 'Sad', 'Happy', 'Surprise', 'Fear', 'Disgust', 'Contempt', 'Neutral']\n",
    "\n",
    "# Calculate class frequencies\n",
    "class_frequencies = train_df[classes].sum().to_dict()\n",
    "# Total number of samples\n",
    "total_samples = len(train_df)\n",
    "# Calculate class weights\n",
    "class_weights = {cls: total_samples / (len(classes) * freq) if freq != 0 else 0 for cls, freq in class_frequencies.items()}\n",
    "print(class_weights)\n",
    "# Convert to list in the order of classes\n",
    "weights_list = [class_weights[cls] for cls in classes]\n",
    "# Convert to PyTorch tensor\n",
    "class_weights_tensor = torch.tensor(weights_list, device='cuda', dtype=torch.float)\n",
    "# Print or return the tensor\n",
    "print(class_weights_tensor)\n",
    "\n",
    "logger.info(f\"Class weights: {class_weights_tensor}\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "text_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "text_model.eval(); text_model.to(device)\n",
    "\n",
    "total_dataset=dict()\n",
    "total_dataloader=dict()\n",
    "for dtype in [\"train\", \"dev\"]:\n",
    "    cur_utts, cur_labs = utils.load_cat_emo_label(label_path, dtype)\n",
    "    cur_wavs = utils.load_audio(audio_path, cur_utts)\n",
    "    if dtype == \"train\":\n",
    "        cur_wav_set = utils.WavSet(cur_wavs, normalize_wav=normalize_wav, use_tp = USE_TIMBRE_PERTURB, tp_prob= TP_PROB)\n",
    "        cur_wav_set.save_norm_stat(MODEL_PATH+\"/train_norm_stat.pkl\")\n",
    "        cur_txt_set = utils.TxtSet(df[df[\"Split_Set\"] == 'Train'].transcription.tolist(), tokenizer)\n",
    "    else:\n",
    "        if dtype == \"dev\":\n",
    "            wav_mean = total_dataset[\"train\"].datasets[0].wav_mean\n",
    "            wav_std = total_dataset[\"train\"].datasets[0].wav_std\n",
    "        elif dtype == \"test\":\n",
    "            wav_mean, wav_std = utils.load_norm_stat(MODEL_PATH+\"/train_norm_stat.pkl\")\n",
    "        cur_wav_set = utils.WavSet(cur_wavs, wav_mean=wav_mean, wav_std=wav_std, normalize_wav=normalize_wav)\n",
    "        cur_txt_set = utils.TxtSet(df[df[\"Split_Set\"] == 'Development'].transcription.tolist(), tokenizer)\n",
    "    ########################################################\n",
    "    cur_bs = BATCH_SIZE // ACCUMULATION_STEP if dtype == \"train\" else 1\n",
    "    is_shuffle=True if dtype == \"train\" else False\n",
    "    ########################################################\n",
    "    cur_emo_set = utils.CAT_EmoSet(cur_labs)\n",
    "    total_dataset[dtype] = utils.CombinedSet([cur_wav_set, cur_emo_set, cur_utts, cur_txt_set])\n",
    "\n",
    "    if((balanced_batch) & (dtype == \"train\")):\n",
    "        logger.info('Using balanced batch')\n",
    "        class_frequencies = train_df[classes].sum().to_dict()\n",
    "        total_samples = len(train_df)\n",
    "        class_weights_ = {cls: 1/np.sqrt(freq) if freq != 0 else 0 for cls, freq in class_frequencies.items()}\n",
    "        weights_list_ = [class_weights_[cls] for cls in classes]\n",
    "        # Convert to PyTorch tensor\n",
    "        class_weights_tensor_ = torch.tensor(weights_list_, device='cuda', dtype=torch.float)\n",
    "        logger.info(f'Using balanced batch. Weights = {class_weights_tensor_}')\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=class_weights_tensor_,               \n",
    "            num_samples=len(total_dataset[dtype]),       \n",
    "            replacement=True                 \n",
    "        )\n",
    "        total_dataloader[dtype] = DataLoader(\n",
    "            total_dataset[dtype], batch_size=cur_bs, sampler=sampler, \n",
    "            pin_memory=True, num_workers=4,\n",
    "            collate_fn=utils.collate_fn_txt_wav_lab_mask\n",
    "        )\n",
    "    else:\n",
    "        total_dataloader[dtype] = DataLoader(\n",
    "        total_dataset[dtype], batch_size=cur_bs, shuffle=is_shuffle, \n",
    "        pin_memory=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn_txt_wav_lab_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966f6fe7-b83d-423d-b6df-a1616b90ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(total_dataloader['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3bd765-8f04-42b9-b513-0efee82ffdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43d7f0d-46cd-4a7c-8d6e-930f8b5d3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(total_dataset[dtype]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcfe3f8-5958-4912-9a51-c4bd476bc201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    8,   38, 1266,    5, 1530,    6,  235,  116,  407,  734,    2,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0bde2-0730-4b84-bf0b-975d10002d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
