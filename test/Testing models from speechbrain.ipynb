{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434e863-5d2b-48f5-bed0-f5ef27e31779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e3c5c6-ad54-44f1-8ca7-71f19638e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# Local modules\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "# 3rd-Party Modules\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import librosa\n",
    "import copy\n",
    "\n",
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel\n",
    "import importlib\n",
    "# Self-Written Modules\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append('../')\n",
    "from benchmark import net\n",
    "from benchmark import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4545b61-6315-4e46-ad96-7c3c5275253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337514a8-84d6-4c23-8620-342112cb709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install speechbrain\n",
    "# !pip install torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244de33b-71ad-4604-b076-d1ec4270263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592f174-6ce0-4bbb-97ad-843698539001",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio==0.13.0 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8810d995-ace1-4df1-88b4-3624ad495b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:speechbrain.utils.torch_audio_backend:This version of torchaudio is old. SpeechBrain no longer tries using the torchaudio global backend mechanism in recipes, so if you encounter issues, update torchaudio.\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b795a437bd94cfe928e05c2a21d1573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading hyperparams.yaml:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "WARNING:speechbrain.utils.torch_audio_backend:This version of torchaudio is old. SpeechBrain no longer tries using the torchaudio global backend mechanism in recipes, so if you encounter issues, update torchaudio.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f3465aead44059b40a7661a5a62808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading embedding_model.ckpt:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac7de90cdbf4167b4209cb134b8281e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading mean_var_norm_emb.ckpt:   0%|          | 0.00/3.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb70ac5901d40b09d9f8c2e8756257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading classifier.ckpt:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a602895c03463085e3f9992387366c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading label_encoder.txt:   0%|          | 0.00/129k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f46c355-66eb-4568-a03d-ba6e6dd6a9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Contempt</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Split_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSP-PODCAST_0002_0033.wav</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSP-PODCAST_0002_0039.wav</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    FileName  Angry  Sad  Happy  Surprise  Fear  Disgust  \\\n",
       "0  MSP-PODCAST_0002_0033.wav    0.0  0.0    0.0       0.0   0.0      0.0   \n",
       "1  MSP-PODCAST_0002_0039.wav    0.0  0.0    0.0       0.0   0.0      0.0   \n",
       "\n",
       "   Contempt  Neutral    Split_Set  \n",
       "0       0.0      1.0  Development  \n",
       "1       0.0      1.0  Development  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../benchmark/processed_labels.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b523aa-8683-4794-8a83-89a733cdc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, fs = torchaudio.load(f\"../data/Audios/{df.FileName.values[0]}\")\n",
    "embeddings = classifier.encode_batch(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2bfbb5-eed0-430d-844e-5c3a3acf86a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca8b0158-8c3d-4a98-8722-4bed680fa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "signal, fs = librosa.load(f\"../data/Audios/{df.FileName.values[0]}\", sr = 16000)\n",
    "embeddings2 = classifier.encode_batch(torch.FloatTensor(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3548b53d-4f48-4fab-becc-f428a80b4617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5435b94c-bc21-4d4b-810b-2f2786c33cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-22.9484, -12.4350,   8.0856,   4.4723, -17.4227])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bf491ce-dfb8-4de2-b255-13f04c595788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-22.9484, -12.4350,   8.0855,   4.4724, -17.4227])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1cff2-a945-4460-8926-002b748dfc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e86ff0-5bf4-4bc0-a5f2-9ebf5c28ba36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230e3bd-9fc6-447c-bce7-f4f29707dd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fba7365-0426-47ee-9aee-d98d786518c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audios\t\t  Labels\t  Speaker_ids.txt  readme.txt\n",
      "Audios.tar.gz\t  Labels.zip\t  Transcripts\n",
      "ForceAligned.zip  Partitions.txt  Transcripts.zip\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a748f636-a9c6-48c7-ac5b-3bdbf569ead6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../data/Audios/MSP-PODCAST_0002_0033.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/Audios/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileName\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../data/Audios/MSP-PODCAST_0002_0033.wav'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(f\"../data/Audios/{df.FileName.values[0]}\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d01298-d8ca-4a8e-b525-c98db9597f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSP-PODCAST_3085_0127.wav',\n",
       " 'MSP-PODCAST_5474_0045.wav',\n",
       " 'MSP-PODCAST_2505_0470.wav',\n",
       " 'MSP-PODCAST_1698_0349.wav',\n",
       " 'MSP-PODCAST_2214_0291.wav',\n",
       " 'MSP-PODCAST_1133_0026_0025.wav',\n",
       " 'MSP-PODCAST_4748_0103_0004.wav',\n",
       " 'MSP-PODCAST_4301_0026_0004.wav',\n",
       " 'MSP-PODCAST_3002_0039.wav',\n",
       " 'MSP-PODCAST_0642_0144.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(f\"../data/Audios/\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae63ebd-a568-421e-8861-386d48e99a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
